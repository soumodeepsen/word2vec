{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49326711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ccfe7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "encoded = {}\n",
    "\n",
    "def simple_preprocessing(text):\n",
    "    sample = text.strip().split()\n",
    "    unique = []\n",
    "    for i in sample: \n",
    "        if i not in unique: unique.append(i)\n",
    "            \n",
    "    vocab.extend(unique)\n",
    "    onehot_encoder()\n",
    "\n",
    "def onehot_encoder():\n",
    "    for idx,word in enumerate(vocab):\n",
    "        encoded[word] = np.zeros(len(vocab))\n",
    "        encoded[word][idx] = 1\n",
    "        \n",
    "def io():\n",
    "    x,y = [],[]\n",
    "    for idx in range(len(vocab)-1):\n",
    "        x.append(encoded[vocab[idx]])\n",
    "        y.append(encoded[vocab[idx+1]])\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "sample = \"This is so good\"    \n",
    "simple_preprocessing(sample)\n",
    "x,y = io()\n",
    "#print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47c3ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec():\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        \n",
    "    def fwd_prop(self,x):\n",
    "        self.x1 = np.dot(self.w0.T,x) + self.b0\n",
    "        self.x2 = np.dot(self.w1.T,self.x1) + self.b1\n",
    "        self.x2 = np.exp(self.x2)\n",
    "        self.x2 /= self.x2.sum()\n",
    "        \n",
    "    \n",
    "    def back_prop(self,x):\n",
    "        db1 = self.x2 * (1 - self.x2)\n",
    "        dw1 = np.dot(self.x1,db1.T)\n",
    "        \n",
    "        b1, w1 = self.b1, self.w1\n",
    "        \n",
    "        self.b1 -= db1\n",
    "        self.w1 -= dw1\n",
    "        \n",
    "        db0 = np.dot(w1,db1)\n",
    "        dw0 = np.dot(x,db0.T)\n",
    "        \n",
    "        self.b0 -= db0\n",
    "        self.w0 -= dw0\n",
    "        \n",
    "        #print(f\"x1_shape = {self.x1.shape}, x2 shape = {self.x2.shape}, db1_shape = {db1.shape}, db1 = {db1}, dw1_shape = {dw1.shape}, dw1 = {dw1}db0_shape = {db0.shape}, db0 = {db0}, dw0_shape = {dw0.shape}, dw0 = {dw0}\")\n",
    "\n",
    "    \n",
    "    def fit(self,x,y,hidden_units = 2, epochs=5,learning_rate=0.001):\n",
    "        self.peripheral_units = x.shape[0]+1\n",
    "        self.hidden_units = hidden_units\n",
    "        \n",
    "        self.w0 = np.random.normal(0,0.05,size = (self.peripheral_units, self.hidden_units))\n",
    "        self.b0 = np.zeros((self.hidden_units,1))\n",
    "        self.w1 = np.random.normal(0,0.05,size = (self.hidden_units, self.peripheral_units))\n",
    "        self.b1 = np.zeros((self.peripheral_units,1))\n",
    "        \n",
    "        for iteration in range(epochs):\n",
    "            for i in range(x.shape[0]):\n",
    "                #print(f\"Input = {x[i].shape}, Expected = {y[i].shape}, init_w0 = {self.w0.shape, self.w0}, init_b0 = {self.b0.shape, self.b0}, init_w1 = {self.w1.shape, self.w1}, init_b1 = {self.b1.shape, self.b1}\")\n",
    "                    \n",
    "                self.fwd_prop(x[i].reshape(-1,1))\n",
    "                l = self.x2 - y[i].reshape(-1,1)\n",
    "                #print(f\"loss = {l}, loss shape = {l.shape}\")\n",
    "                self.back_prop(x[i].reshape(-1,1))\n",
    "                \n",
    "                \n",
    "    def predict(self,x):\n",
    "        self.fwd_prop(x.reshape(-1,1))\n",
    "        return self.x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d76162",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"datasets/The_Oxford_5000.txt\",\"r\")\n",
    "data = file.read()\n",
    "print(data[:100])\n",
    "vocabulary = re.findall(\"\\\\n\\w+\",data)\n",
    "vocabulary = [i[1:] for i in vocabulary]\n",
    "vocabulary[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32001b55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word2vec = Word2Vec()\n",
    "word2vec.fit(x,y,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f9be0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.29719724e+00, -5.40598692e+00],\n",
       "       [ 2.65603746e+00, -6.41708469e+00],\n",
       "       [ 1.52307557e+00, -3.73524239e+00],\n",
       "       [-5.66538214e-02, -6.09673620e-03]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "65a09393",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = word2vec.predict(encoded[\"is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5efb9f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.argmax(p)\n",
    "p = np.zeros(p.shape)\n",
    "p[m] = 1\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
